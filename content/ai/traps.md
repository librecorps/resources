---
title: "Common Traps When Building AI Systems"
date: 2019-09-03T11:02:05+06:00
type: "post"
weight : 2
---
## **Avoiding Common ML Traps**

_Assessing common mistakes that lead to unintended side effects._

**The Framing Trap**

_Failure to model the entire system over which a social criterion, such as fairness, will be enforced._

For this trap, we will want to look at our outcome variables. Are these variables a proxy of the actual outcome you wish to achieve? What evidence of existing negative bias currently exists with regards to these variables?

**The Portability Trap**

_Failure to understand how repurposing algorithmic solutions designed for one social context_

_may be misleading, inaccurate, or otherwise do harm when applied to a different context_

Here, you will want to be fully understanding of the context in which this model is being built for and the context in which you will be using it. There should be clear documentation distributed across the entire team focusing on this. What stakeholders do you expect to have an impact on where this technology will be used. Are they informed?

**The Formalism Trap**

_Failure to account for the full meaning of social concepts such as fairness, which can be_

_procedural, contextual, and contestable, and cannot be resolved through mathematical formalisms_

How does your chosen outcome continue to implement and solve existing procedural &quot;catches&quot; in order to ensure the decision making process is fair? What method of recourse are available for those who are unfairly judged?

**The Ripple Effect Trap**

_Failure to understand how the insertion of technology into an existing social system_

_changes the behaviors and embedded values of the pre-existing system_

How do you think the introduction of this recommendation system will affect your users? What changes in behavior do you intend to change? Can you think of any possible changes in behavior that you don&#39;t intend as a result of your software?

**The Solutionism Trap**

_Failure to recognize the possibility that the best solution to a problem may not involve technology_

Will this technology elevate social values which can be quantified? Will it devalue those which cannot? What values might take a back seat if this technology is implemented?

